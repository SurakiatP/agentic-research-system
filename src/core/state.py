from typing import List, Optional, Any, Sequence
from typing_extensions import TypedDict
from pydantic import BaseModel, Field
from langchain_core.messages import BaseMessage

class ResearchResult(BaseModel):
    """
    Structured result from a single research step.
    
    Attributes:
        query (str): The specific search query used.
        content (str): The raw content or summary found.
        source (str): The source URL or citation.
        type (str): The type of source (web, arxiv, etc).
        confidence (float): A score from 0.0 to 1.0 indicating reliability.
    """
    query: str = Field(description="The specific search query used")
    content: str = Field(description="The raw content or summary found")
    source: str = Field(description="The source URL or citation")
    type: str = Field(description="The type of source (web, arxiv, etc)", default="web")
    confidence: float = Field(description="A score from 0.0 to 1.0 indicating reliability", default=1.0)

class SubQuery(BaseModel):
    """
    A single sub-question generated by the Manager Agent.
    
    Attributes:
        original_query (str): The main user query this relates to.
        sub_query (str): The specific question to research.
        reasoning (str): Why this question is important.
        status (str): Current status (pending, completed, failed).
    """
    original_query: str = Field(description="The main user query this relates to")
    sub_query: str = Field(description="The specific question to research")
    reasoning: str = Field(description="Why this question is important")
    status: str = Field(description="Current status (pending, completed, failed)", default="pending")

class AgentState(TypedDict):
    """
    The main state of the LangGraph workflow.
    
    Attributes:
        messages (Sequence[BaseMessage]): Chat history.
        user_query (str): The initial query from the user.
        sub_queries (List[SubQuery]): List of broken-down questions.
        research_results (List[ResearchResult]): Accumulated findings.
        final_answer (str): The synthesized final response.
        next_step (str): The next node to execute.
        loop_count (int): Safety counter to prevent infinite loops.
        cache_hit (bool): Whether the initial cache check found a result.
        cached_answer (str): The cached answer if cache_hit is True.
    """
    messages: Sequence[BaseMessage]
    user_query: str
    sub_queries: List[SubQuery]
    research_results: List[ResearchResult]
    final_answer: Optional[str]
    next_step: Optional[str]
    loop_count: int
    cache_hit: Optional[bool]
    cached_answer: Optional[str]
    # Router Agent fields
    route_decision: Optional[str]          # "general_chat" | "deep_research"
    general_chat_answer: Optional[str]     # Answer from general chat mode
    # Reflection / HITL #2 fields
    reflection_count: int                  # Number of reflection loops (max 3)
    user_approved_final: Optional[bool]    # HITL #2: user approved final answer?
    reflection_feedback: Optional[str]     # User feedback when rejecting
    # Evaluation tracking
    tools_called: List[str]                # Tools invoked during research (for eval)
